{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Classification with KerasCV\n",
    "\n",
    "**Author:** [lukewood](https://lukewood.xyz)<br>\n",
    "**Date created:** 03/28/2023<br>\n",
    "**Last modified:** 03/28/2023<br>\n",
    "**Description:** Use KerasCV to train powerful image classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This guide demonstrates KerasCV's modular approach to solving image\n",
    "classification problems at two levels of complexity:\n",
    "\n",
    "- Inference with a pretrained classifier\n",
    "- Fine-tuning a pretrained backbone\n",
    "\n",
    "We use Professor Keras, the official Keras mascot, as a\n",
    "visual reference for the complexity of the material:\n",
    "\n",
    "![](https://storage.googleapis.com/keras-nlp/getting_started_guide/prof_keras_evolution.png)\n",
    "\n",
    "Please note that due to classification being a pretty simple use case,\n",
    "this guide only covers beginner and intermediate workflows.\n",
    "Advanced and expert workflows may be found in [other KerasCV guides](https://keras.io/guides/keras_cv/)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "!!pip install -q --upgrade git+https://github.com/keras-team/keras-cv.git tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import keras_cv\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Inference with a pretrained classifier\n",
    "\n",
    "![](https://storage.googleapis.com/keras-nlp/getting_started_guide/prof_keras_beginner.png)\n",
    "\n",
    "Let's get started with the simples KerasCV API: a pretrained classifier.\n",
    "In this example, we will build a Dogs vs Cats classifier using a model that was\n",
    "pretrained on the ImageNet dataset.\n",
    "\n",
    "The highest level module in KerasCV is a *task*. A *task* is a `keras.Model`\n",
    "consisting of a (generally pretrained) backbone model and task-specific layers.\n",
    "Here's an example using `keras_cv.models.ImageClassifier` with a EfficientNetV2S\n",
    "Backbone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "classifier = keras_cv.models.ImageClassifier.from_preset(\n",
    "    \"efficientnetv2-s_imagenet_classifier\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "You may notice a small deviation from the old `keras.applications` API; where\n",
    "you would construct the class with `EfficientNetV2S(weights=\"imagenet\")`.\n",
    "While the old API was great for classification, it did not scale effectively to\n",
    "other use cases that required complex architectures, like object deteciton and\n",
    "semantic segmentation.\n",
    "\n",
    "Now that we have a classifier build, lets take our model for a spin!\n",
    "Let's run inference on a picture of  a cute cat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "filepath = tf.keras.utils.get_file(origin=\"https://i.imgur.com/9i63gLN.jpg\")\n",
    "image = keras.utils.load_img(filepath)\n",
    "image = np.array(image)\n",
    "keras_cv.visualization.plot_image_gallery(\n",
    "    [image],\n",
    "    rows=1,\n",
    "    cols=1,\n",
    "    value_range=(0, 255),\n",
    "    show=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Lets also fetch the class mapping for ImageNet.  I have this class mapping\n",
    "hosted in a GitHub gist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class_mapping = keras.utils.get_file(\n",
    "    origin=\"https://gist.githubusercontent.com/LukeWood/368e2e89bb0e36bd34ff7043e0247289/raw/0615d1e88a93d4e971bf2dea0cfc52f30a12dd99/imagenet%2520mapping\"\n",
    ")\n",
    "class_mapping = json.load(open(class_mapping, \"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Let's get some predictions from our classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "predictions = classifier.predict(np.expand_dims(image, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Predictions come in the form of softmax-ed category rankings.\n",
    "We can find the index of the top classes using a simple argsort function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "top_classes = predictions[0].argsort(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "In order to decode the class mappings, we can construct a mapping from\n",
    "category indices to ImageNet class names.\n",
    "For conveneince, I've stored the ImageNet class mapping in a GitHub gist.\n",
    "Let's download and load it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "classes = keras.utils.get_file(\n",
    "    origin=\"https://gist.githubusercontent.com/LukeWood/62eebcd5c5c4a4d0e0b7845780f76d55/raw/fde63e5e4c09e2fa0a3436680f436bdcb8325aac/ImagenetClassnames.json\"\n",
    ")\n",
    "with open(classes, \"rb\") as f:\n",
    "    classes = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Now we can simply look up the class names via index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "top_two = [classes[str(i)] for i in top_classes[-2:]]\n",
    "print(\"Top two classes are:\", top_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Great!  Both of these appear to be correct!\n",
    "But what if you don't care about the\n",
    "velvet blanket?\n",
    "Perhaps instead, you only want to know if a cat is in the image or not.\n",
    "This can be solved using fine tuning your own classifier.\n",
    "\n",
    "# Fine tuning a pretrained classifier\n",
    "\n",
    "![](https://storage.googleapis.com/keras-nlp/getting_started_guide/prof_keras_intermediate.png)\n",
    "\n",
    "When labeled images specific to our task are available, fine-tuning a custom\n",
    "classifier can improve performance. If we want to train a Cats vs Dogs\n",
    "Classifier, using explicitly labeled Cat vs Dog data should perform better than\n",
    "the generic classifier data! And for many tasks, no relevant pretrained model\n",
    "will be available (e.g., categorizing images specific to your application).\n",
    "\n",
    "The biggest difficulty when fine-tuning a KerasCV model is loading and augmenting\n",
    "your data.  Luckily, we've handled the second half for you, so all you'll have\n",
    "to do is load your own data.\n",
    "\n",
    "First, let's setup our data pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "data, dataset_info = tfds.load(\"cats_vs_dogs\", with_info=True, as_supervised=True)\n",
    "train_steps_per_epoch = dataset_info.splits[\"train\"].num_examples // BATCH_SIZE\n",
    "train_dataset = data[\"train\"]\n",
    "\n",
    "IMAGE_SIZE = (224, 224)\n",
    "num_classes = dataset_info.features[\"label\"].num_classes\n",
    "\n",
    "random_crop = keras_cv.layers.Resizing(224, 224, crop_to_aspect_ratio=True)\n",
    "\n",
    "\n",
    "def package_dict(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = random_crop(image)\n",
    "    label = tf.one_hot(label, num_classes)\n",
    "    return {\"images\": image, \"labels\": label}\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.shuffle(10 * BATCH_SIZE).map(\n",
    "    package_dict, num_parallel_calls=AUTOTUNE\n",
    ")\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "images = next(iter(train_dataset.take(1)))[\"images\"]\n",
    "keras_cv.visualization.plot_image_gallery(images, value_range=(0, 255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Next, lets assemble a `keras_cv` augmentation pipeline.\n",
    "In this guide, we use the standard pipeline\n",
    "[CutMix, MixUp, and RandAugment](https://keras.io/guides/keras_cv/cut_mix_mix_up_and_rand_augment/)\n",
    "augmentation pipeline.  More information on the behavior of these augmentations\n",
    "may be found in their\n",
    "[corresponding Keras.io guide](https://keras.io/guides/keras_cv/cut_mix_mix_up_and_rand_augment/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "augmenter = keras.Sequential(\n",
    "    layers=[\n",
    "        keras_cv.layers.RandomFlip(),\n",
    "        keras_cv.layers.RandAugment(value_range=(0, 255)),\n",
    "        keras_cv.layers.CutMix(),\n",
    "        keras_cv.layers.MixUp(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = train_dataset.map(augmenter, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "images = next(iter(train_dataset.take(1)))[\"images\"]\n",
    "keras_cv.visualization.plot_image_gallery(images, value_range=(0, 255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Next let's construct our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "backbone = keras_cv.models.EfficientNetV2Backbone.from_preset(\n",
    "    \"efficientnetv2-s_imagenet\",\n",
    ")\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        backbone,\n",
    "        keras.layers.GlobalMaxPooling2D(),\n",
    "        keras.layers.Dense(2, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=tf.optimizers.SGD(learning_rate=0.01),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "All that is left to do is construct a standard Keras `model.fit()` loop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def unpackage_data(inputs):\n",
    "    return inputs[\"images\"], inputs[\"labels\"]\n",
    "\n",
    "\n",
    "train_dataset.map(unpackage_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "model.fit(train_dataset.map(unpackage_data, num_parallel_calls=tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Let's look at how our model performs after the fine tuning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(np.expand_dims(image, axis=0))\n",
    "\n",
    "classes = {0: \"cat\", 1: \"dog\"}\n",
    "print(\"Top class is:\", classes[predictions[0].argmax()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Awesome!  Looks like the model correctly classified the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "KerasCV makes image classification easy.\n",
    "Making use of the KerasCV `ImageClassifier` API, pretrained weights, and the\n",
    "KerasCV data augmentations allows you to train a powerful classifier in `<50`\n",
    "lines of code.\n",
    "\n",
    "As a follow up exercise, give the following a try:\n",
    "\n",
    "- Fine tune a KerasCV classifier on your own dataset\n",
    "- Learn more about [KerasCV's data augmentations](https://keras.io/guides/keras_cv/cut_mix_mix_up_and_rand_augment/)\n",
    "- Check out how we train our models on [ImageNet](https://github.com/keras-team/keras-cv/blob/master/examples/training/classification/imagenet/basic_training.py)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "classification_with_keras_cv",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}